{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing avant utilisation des modèles**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook vise à explorer rapidement la base de données pour avoir une idée de se composition, la répartition et éventuels déséquilibres entre les classes, les caractéristiques des textes à analyser. Cela est éventuellement l'occasion de détecter des erreurs de textes (encodage erroné au moment d'enregistrer/lire les demandes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour faciliter la mise à jour des fonctions écrites dans func_custom sans avoir à redémarrer le kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages classiques\n",
    "import pandas as pd\n",
    "\n",
    "# Custom package\n",
    "import func_custom as fc\n",
    "\n",
    "# NLP\n",
    "import unidecode\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data/data_train.xlsx\",\n",
    "                    usecols = [\"label\", \"message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Analyse, justification et étapes du preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si certaines étapes sont standards et ne nécessite pas d'explication (mettre en .lower() par exemple), regardons certains points plus particulièrement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Application de .lower() : non commenté"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Encodage des accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prélèvement', 'époux', 'à', 'impôts']\n",
      "['prélèvement', 'époux', 'à', 'impôts']\n"
     ]
    }
   ],
   "source": [
    "first_message = df[\"message\"][0].split()\n",
    "data_encodage = [first_message[i] for i in [21, 37, 43, 46]]\n",
    "print(data_encodage)\n",
    "keyboard_encodage = [\"prélèvement\", \"époux\", \"à\", \"impôts\"]\n",
    "print(keyboard_encodage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'pre\\\\u0301le\\\\u0300vement', b'e\\\\u0301poux', b'a\\\\u0300', b'impo\\\\u0302ts']\n",
      "[b'pr\\\\xe9l\\\\xe8vement', b'\\\\xe9poux', b'\\\\xe0', b'imp\\\\xf4ts']\n",
      "\n",
      "[b'pr\\\\xe9l\\\\xe8vement', b'\\\\xe9poux', b'\\\\xe0', b'imp\\\\xf4ts']\n",
      "[b'pr\\\\xe9l\\\\xe8vement', b'\\\\xe9poux', b'\\\\xe0', b'imp\\\\xf4ts']\n"
     ]
    }
   ],
   "source": [
    "print([t.encode(\"unicode_escape\") for t in data_encodage])\n",
    "print([t.encode(\"unicode_escape\") for t in keyboard_encodage])\n",
    "print(\"\")\n",
    "print([unicodedata.normalize(\"NFKC\", t).encode(\"unicode_escape\") for t in data_encodage])\n",
    "print([unicodedata.normalize(\"NFKC\", t).encode(\"unicode_escape\") for t in keyboard_encodage])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faudra une étape de normalisation avec `unicodedata.normalize(\"NFKC\", text)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Gestion de la ponctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les signes de ponctuations sont tous remplacés par un _espace_ pour anticiper sur les failles du tokenizer de nltk. Typiquement en cas d'erreur de phrase, d'absence d'espace, surtout autour de mots inconnus le tokenizer rate complètement. Exemple avec cette phrase qui contient `0000.L'XXXXX́e` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, J'ai divorcé en 0000.J'ai commencé à verser une pension alimentaire à partir de septembre 0000.L'XXXXX́e dernière j'ai donc versé un XXXXX́e pleine.Par rapport au prélèvement à la source comment cela ce passe-t-il sachant que j'aurais plus à déduire pour l'XXXXX́e dernière que 0000?actuellement je suis prélever par rapport à 0000?y-aura t-il un remboursement en fin d'XXXXX́e?Peut-on modifier le prélèvement à la source en cours d'XXXXX́e? D'avance merci Cordialement XXXXX XXXXX\n"
     ]
    }
   ],
   "source": [
    "message_test = df[df[\"message\"].str.contains(\"0000.L'XXXXX́e\")][\"message\"].values[0]\n",
    "print(message_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(message_test, language = \"french\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate un problème avec le tokenizer qui persisterait si on supprimait simplement la ponctuation, je préfère donc la remplacer par un espace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pension',\n",
       " 'alimentaire',\n",
       " 'à',\n",
       " 'partir',\n",
       " 'de',\n",
       " 'septembre',\n",
       " \"0000.L'XXXXX́e\",\n",
       " 'dernière',\n",
       " \"j'ai\",\n",
       " 'donc']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(fc.replace_punctuation_with_space(message_test), language = \"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['partir',\n",
       " 'de',\n",
       " 'septembre',\n",
       " '0000',\n",
       " 'L',\n",
       " 'XXXXX́e',\n",
       " 'dernière',\n",
       " 'j',\n",
       " 'ai',\n",
       " 'donc']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[15:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'utilise ici le tokenizer par défaut de nltk en français"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Gestion des stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En combinant tous les éléments précédents dans la fonction `preprocess_stopwords` dans `func_custom.py` étudions désormais le traitement des stopwords. \n",
    "Commençons pas ne prendre en compte que ceux de base dans nltk :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_french = set(stopwords.words('french'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xxxxx           1777\n",
       "taux            1323\n",
       "revenus          712\n",
       "prélèvement      670\n",
       "bonjour          624\n",
       "source           526\n",
       "a                522\n",
       "cordialement     413\n",
       "plus             366\n",
       "merci            365\n",
       "€                353\n",
       "déclaration      300\n",
       "comment          271\n",
       "faire            260\n",
       "bien             256\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ' '.join(df[\"message\"].dropna())\n",
    "tokens_clean = fc.preprocess_stopwords(text, stopwords_french)\n",
    "pd.DataFrame(tokens_clean).value_counts().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que la simple inclusion des stopwords par défaut de nltk ne suffira pas, des éléments spécifiques au jeu de données (`xxxxx` et `0000` issus de pseudonymisation, `bonjour` et `merci` et mots de politesse du fait qu'il s'agit de message écrits par des particuliers à la DGFIP). On peut alors compléter de manière _ad hoc_ cette liste en regardant à l'oeil nu ces éléments. Si l'exerice consiste cependant à distinguer les messages \"polis\" des autres alors cette liste de stopwords n'est absolument pas pertinente.\n",
    "\n",
    "TF-IDF aurait dans une certaine mesure pu tenir compte de ces mots largement présent dans le corpus et peu informatif, autant traiter ce problème à la racine ce qui limitera la taille des données à traiter par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_adhoc = {\"à\", \"xxxxx\", \"bonjour\", \"a\", \"cordialement\", \"merci\", \"xxxxx́e\", \"xxxxx́\", \"k€\", \"donc\", \"car\", \"cette\", \"cela\",\n",
    "                  \"être\", \"si\", \"même\", \"faire\", \"avoir\", \"remercie\", \"madame\", \"monsieur\"}\n",
    "stopwords_complete = stopwords_french.union(stopwords_adhoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "taux           1323\n",
       "revenus         712\n",
       "prélèvement     670\n",
       "source          526\n",
       "plus            366\n",
       "déclaration     300\n",
       "comment         271\n",
       "bien            256\n",
       "situation       255\n",
       "mois            249\n",
       "dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_clean = fc.preprocess_stopwords(text, stopwords_complete)\n",
    "pd.DataFrame(tokens_clean).value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Suppression des caractères de taille 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour prendre en compte des caractères spéciaux ou des lettres uniques suite au tokenizer, qui n'apporteront pas d'informations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 (Non implémenté) prise en compte des fautes d'orthographe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Stemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Agrégation dans une fonction unique et application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"message_clean\"] = df[\"message\"].apply(lambda x : fc.preprocess_text(x, stopwords_complete))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, J'ai une question sur le prélèvement à la source. Je suis pacsée depuis 0000 mais l'XXXXX́e dernière nous avons choisi de faire une déclaration séparée. Je viens de faire une simulation pour les revenus de 0000. Si nous déclarons ensemble, le taux du foyer serait de 0000.0000% (cf ma pièce jointe). Comment cela se traduit-il sur le prélèvement ? car il est indiqué que ce taux s 'applique pour le foyer. va-t-on nous prélever 0000.0000 % sur chaque salaire ou bien sur un des deux ? Je vous remercie pour votre réponse. Cordialement, XXXXX XXXXX\n",
      "question prélèvement source pacsée depuis dernière choisi déclaration séparée viens simulation revenus déclarons ensemble taux foyer cf pièce jointe comment traduit prélèvement indiqué taux applique foyer va prélever chaque salaire bien deux réponse\n"
     ]
    }
   ],
   "source": [
    "message_test = df.sample(1)\n",
    "print(message_test[\"message\"].values[0])\n",
    "print(message_test[\"message_clean\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"data/data_clean.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/data_clean.csv\", \n",
    "                sep = \";\",\n",
    "                index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
